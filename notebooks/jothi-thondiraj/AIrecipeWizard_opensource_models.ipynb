{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/SDS_Projects/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import InferenceClient\n",
    "from PIL import Image\n",
    "import gradio as gr\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate recipe from ingredients\n",
    "def generate_recipe(ingredients: str, model_name_recipe: str, token: str) -> str:\n",
    "    \"\"\"\n",
    "    Generates a recipe based on input ingredients using an LLM.\n",
    "    Args:\n",
    "        ingredients (str): Ingredients input by the user.\n",
    "        model_name_recipe (str): Hugging Face model for text generation.\n",
    "        token (str): API token for Hugging Face authentication.\n",
    "    Returns:\n",
    "        str: Generated recipe text.\n",
    "    \"\"\"\n",
    "    prompt = f\"Generate a recipe using the following ingredients: {ingredients}.\\\n",
    "               Write the recipe in detail along with a suitable title.\\\n",
    "               Add a youtube link for the recipe in the end.\"\n",
    "    client = InferenceClient(model_name_recipe, token=token)\n",
    "    try:\n",
    "        response = client.post(\n",
    "            json={\n",
    "                \"inputs\": prompt,\n",
    "                \"parameters\": {\"max_new_tokens\": 500},\n",
    "                \"task\": \"text-generation\",\n",
    "            }\n",
    "        )\n",
    "        return json.loads(response.decode())[0][\"generated_text\"]\n",
    "    except Exception as e:\n",
    "        return f\"Error generating recipe: {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate image of the recipe\n",
    "def generate_image(recipe_title: str, model_name_image: str, token: str) -> Image.Image:\n",
    "    \"\"\"\n",
    "    Generates an image based on the recipe title using a text-to-image model.\n",
    "    Args:\n",
    "        recipe_title (str): Title of the recipe to use as the prompt.\n",
    "        model_name_image (str): Hugging Face model for image generation.\n",
    "        token (str): API token for Hugging Face authentication.\n",
    "    Returns:\n",
    "        PIL.Image.Image: Generated image.\n",
    "    \"\"\"\n",
    "    client = InferenceClient(model_name_image, token=token)\n",
    "    try:\n",
    "        prompt = f\"A photo the dish: {recipe_title}, showing delicious presentation.\"\n",
    "        return client.text_to_image(prompt)\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating image: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradio function that combines both recipe generation and image generation\n",
    "def generate_recipe_and_image(message: str, history):\n",
    "    token = os.getenv(\"API_Token_HF_AIrecipe\")  # Ensure your Hugging Face token is set in environment variables\n",
    "    model_name_recipe = \"microsoft/Phi-3-mini-4k-instruct\"  # Replace with the LLM model of your choice\n",
    "    model_name_image = \"prompthero/openjourney\"  # Replace with the image generation model of your choice\n",
    "    \n",
    "    # Generate recipe\n",
    "    recipe_text = generate_recipe(message, model_name_recipe, token)\n",
    "    prompt_to_remove = f\"Generate a recipe using the following ingredients: {message}. Write the recipe in detail along with a suitable title.\"\n",
    "    if prompt_to_remove in recipe_text:\n",
    "        recipe_text = recipe_text.replace(prompt_to_remove, \"\").strip()\n",
    "    # print(\"recipe_text:\",recipe_text)\n",
    "    # Extract recipe title from generated recipe text\n",
    "    lines = recipe_text.split(\"\\n\")\n",
    "    for line in lines:\n",
    "        if line.lower().startswith(\"title:\"):  # Case-insensitive match\n",
    "            recipe_title = line.replace(\"Title:\", \"\").strip()  # Extract and clean title\n",
    "            break \n",
    "    print(\"recipe_title\",recipe_title)    \n",
    "    # Generate image for the recipe\n",
    "    recipe_image = generate_image(recipe_title, model_name_image, token)\n",
    "    image_path = \"./recipe_image.png\"\n",
    "    recipe_image.save(image_path, format=\"PNG\")\n",
    "    \n",
    "    # Combine text and image\n",
    "    return recipe_text, gr.Image(value=image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradio UI\n",
    "with gr.Blocks(theme=gr.themes.Monochrome()) as demo:\n",
    "    gr_image = gr.Image(render=False)\n",
    "    with gr.Row():\n",
    "        with gr.Column(scale=4):\n",
    "            gr.Markdown(\"<center><h1>AI Recipe Chatbot</h1></center>\")\n",
    "            chatbot = gr.ChatInterface(\n",
    "                generate_recipe_and_image,\n",
    "                examples=[\"chicken, rice, tomatoes, onions, spices\", \"oats, milk, fruits\", \"Noodles, Tofu, Soy sauce\"],\n",
    "                type=\"messages\",\n",
    "                additional_outputs=[gr_image]\n",
    "            )\n",
    "        with gr.Column(scale=1):\n",
    "            gr.Markdown(\"<center><h1>Recipe Image</h1></center>\")\n",
    "            # recipe_image = gr.Image(label=\"Generated Recipe Image\")\n",
    "            gr_image.render()      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo.launch()\n",
    "# use youtube video link."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SDS_Projects",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
